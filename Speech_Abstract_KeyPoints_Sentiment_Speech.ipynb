{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtvsuAcXnYH2zJsClrWgsz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amancharla/OpenAIEx/blob/main/Speech_Abstract_KeyPoints_Sentiment_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF9dZKi7oHLD",
        "outputId": "5e961679-a6cf-4cd6-9271-1d10e5fc97c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/221.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/tutorials/meeting-minutes\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "eF9Jz4HN5Sn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRGG7HpRoiFy",
        "outputId": "9ef610fe-6edc-46b8-e751-4954afd4d66e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdSMl-L0pW9E",
        "outputId": "547f5adf-7a54-40fb-eddc-d0730e890b88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai  # for calling the OpenAI API\n",
        "import pandas as pd  # for storing text and embeddings data\n",
        "import tiktoken  # for counting tokens"
      ],
      "metadata": {
        "id": "KjPjXdJhofGD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=openai.api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "7g_LunkeooT1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def transcribe_audio(audio_file_path):\n",
        "    with open(audio_file_path, 'rb') as audio_file:\n",
        "        transcription = client.audio.transcriptions.create(model=\"whisper-1\",file=audio_file)\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "pxQAPm8jp1ne"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def abstract_summary_extraction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following text and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "xbaysLpPqBt-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def key_points_extraction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return  response.choices[0].message.content"
      ],
      "metadata": {
        "id": "cLUwxNhvqFhc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def action_item_extaction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return  response.choices[0].message.content"
      ],
      "metadata": {
        "id": "hw2mCasfqI_3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return  response.choices[0].message.content"
      ],
      "metadata": {
        "id": "bL1GxnoTqNDx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_docx(minutes, filename):\n",
        "    doc = Document()\n",
        "    for key, value in minutes.items():\n",
        "        # Replace underscores with spaces and capitalize each word for the heading\n",
        "        heading = ' '.join(word.capitalize() for word in key.split('_'))\n",
        "        doc.add_heading(heading, level=1)\n",
        "        doc.add_paragraph(value)\n",
        "        # Add a line break between sections\n",
        "        doc.add_paragraph()\n",
        "    doc.save(filename)"
      ],
      "metadata": {
        "id": "bg6j9Xc3qS9L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def meeting_minutes(transcription):\n",
        "    abstract_summary = abstract_summary_extraction(transcription)\n",
        "    key_points = key_points_extraction(transcription)\n",
        "    action_items = action_item_extaction(transcription)\n",
        "    sentiment = sentiment_analysis(transcription)\n",
        "    return {\n",
        "        'abstract_summary': abstract_summary,\n",
        "        'key_points': key_points,\n",
        "        'action_items': action_items,\n",
        "        'sentiment': sentiment\n",
        "    }"
      ],
      "metadata": {
        "id": "lMspOnAap6x0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file_path = \"/content/EarningsCall.mp3\"\n",
        "transcription = transcribe_audio(audio_file_path)\n",
        "print(transcription.text)\n",
        "#text1=\"Good afternoon, everyone, and welcome to FinTech Plus Sync's 2nd quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar Q2 with a revenue of $125 million, a 25% increase year over year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our EBITDA has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially, thanks to the expansion of our high-yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities. We've also invested $25 million in AAA-rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion, with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. Our LTVCAC ratio is at an impressive 3.5%. In terms of risk management, we have a value-at-risk model in place, with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage, and have a healthy tier-one capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million and 8% quarter-over-quarter growth, driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming IPO of our fintech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us, and we look forward to an even more successful Q3. Thank you so much.\"\n",
        "\n",
        "minutes = meeting_minutes(transcription.text)\n",
        "print(minutes)\n",
        "\n",
        "save_as_docx(minutes, 'meeting_minutes.docx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6nStS1zqXw7",
        "outputId": "34a39fa8-6a62-4fba-cb4a-47a22f60254c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good afternoon, everyone, and welcome to FinTech Plus Sync's 2nd quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar Q2 with a revenue of $125 million, a 25% increase year over year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our EBITDA has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially, thanks to the expansion of our high-yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities. We've also invested $25 million in AAA-rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion, with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. Our LTVCAC ratio is at an impressive 3.5%. In terms of risk management, we have a value-at-risk model in place, with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage, and have a healthy tier-one capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million and 8% quarter-over-quarter growth, driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming IPO of our fintech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us, and we look forward to an even more successful Q3. Thank you so much.\n",
            "{'abstract_summary': \"FinTech Plus Sync reported a successful Q2 2023, with a 25% YoY increase in revenue to $125 million, a gross profit margin of 58%, and a 30% EBITDA margin. The company's net income rose to $16 million, up from $10 million in Q2 2022. The expansion of their high-yield savings product line and the new RoboAdvisor platform have significantly grown their total addressable market. They have diversified their asset-backed securities portfolio and invested $25 million in AAA-rated corporate bonds. The company's total assets reached $1.5 billion, with total liabilities at $900 million, resulting in a solid equity base of $600 million. They have seen substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. The company's forecast for the next quarter is positive, expecting revenue around $135 million and 8% QoQ growth, driven by their blockchain solutions and AI-driven predictive analytics. They also anticipate raising $200 million from the upcoming IPO of their fintech subsidiary, Pay Plus.\\n\", 'key_points': \"1. FinTech Plus Sync reported a successful Q2 2023 with a revenue of $125 million, a 25% increase year over year.\\n2. The company's gross profit margin stands at 58%, attributed to cost efficiencies from their scalable business model.\\n3. The EBITDA has surged to $37.5 million, translating to a 30% EBITDA margin.\\n4. Net income for the quarter rose to $16 million, a significant increase from $10 million in Q2 2022.\\n5. The total addressable market has grown due to the expansion of the high-yield savings product line and the new RoboAdvisor platform.\\n6. The company diversified its asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities.\\n7. FinTech Plus Sync invested $25 million in AAA-rated corporate bonds to enhance risk-adjusted returns.\\n8. The company's total assets reached $1.5 billion, with total liabilities at $900 million, resulting in a solid equity base of $600 million.\\n9. The debt-to-equity ratio stands at 1.5, a healthy figure considering the company's expansionary phase.\\n10. The company reported substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%.\\n11. The company has a value-at-risk model in place, indicating a maximum loss of $5 million in the next trading day at a 99% confidence level.\\n12. The company maintains a healthy tier-one capital ratio of 12.5%.\\n13. The forecast for the next quarter is positive, with expected revenue around $135 million and 8% quarter-over-quarter growth.\\n14. The growth is expected to be driven by blockchain solutions and AI-driven predictive analytics.\\n15. The company is preparing for the IPO of its fintech subsidiary, Pay Plus, expected to raise $200 million, which will significantly increase liquidity and support aggressive growth strategies.\", 'action_items': \"No specific tasks, assignments, or actions were identified in the text. The text is a summary of a company's financial performance and future expectations, but does not include any specific action items or tasks.\", 'sentiment': \"The sentiment of the text is overwhelmingly positive. The speaker, John Doe, CEO of FinTech Plus, discusses the company's successful second quarter in 2023, highlighting significant increases in revenue, gross profit margin, EBITDA, and net income. He also mentions the company's successful diversification of its portfolio, substantial organic user growth, and effective risk management. The positive sentiment is further reinforced by the optimistic forecast for the next quarter, the upcoming IPO of a subsidiary, and the gratitude expressed towards shareholders. The language used is confident and upbeat, indicating a successful period for the company and a positive outlook for the future.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "#client = OpenAI()\n",
        "key_points = key_points_extraction(transcription.text)\n",
        "speech_file_path = Path(\"speech.mp3\").parent / \"speech.mp3\"\n",
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1\",\n",
        "  voice=\"alloy\",\n",
        "  input=key_points\n",
        ")\n",
        "\n",
        "response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "XOCOQVVZ1d8b"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1-hd\",\n",
        "    voice=\"alloy\",\n",
        "    input=key_points\n",
        ")\n",
        "\n",
        "response.stream_to_file(\"output.mp3\")"
      ],
      "metadata": {
        "id": "r9cKykky5kgn"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}