{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RVkoVgKtXkl"
      },
      "source": [
        "## Named Entity Recognition (NER) to Enrich Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntXohSHQtXkp"
      },
      "source": [
        "`Named Entity Recognition` (NER) is a `Natural Language Processing` task that identifies and classifies named entities (NE) into predefined semantic categories (such as persons, organizations, locations, events, time expressions, and quantities). By converting raw text into structured information, NER makes data more actionable, facilitating tasks like information extraction, data aggregation, analytics, and social media monitoring.\n",
        "\n",
        "This notebook demonstrates how to carry out NER with [chat completion](https://platform.openai.com/docs/api-reference/chat) and [functions-calling](https://platform.openai.com/docs/guides/gpt/function-calling) to enrich a text with links to a knowledge base such as Wikipedia:\n",
        "\n",
        "**Text:**\n",
        "\n",
        "*In Germany, in 1440, goldsmith Johannes Gutenberg invented the movable-type printing press. His work led to an information revolution and the unprecedented mass-spread of literature throughout Europe. Modelled on the design of the existing screw presses, a single Renaissance movable-type printing press could produce up to 3,600 pages per workday.*\n",
        "\n",
        "**Text enriched with Wikipedia links:**\n",
        "\n",
        "*In [Germany](https://en.wikipedia.org/wiki/Germany), in 1440, goldsmith [Johannes Gutenberg]() invented the [movable-type printing press](https://en.wikipedia.org/wiki/Movable_Type). His work led to an [information revolution](https://en.wikipedia.org/wiki/Information_revolution) and the unprecedented mass-spread of literature throughout [Europe](https://en.wikipedia.org/wiki/Europe). Modelled on the design of the existing screw presses, a single [Renaissance](https://en.wikipedia.org/wiki/Renaissance) [movable-type printing press](https://en.wikipedia.org/wiki/Movable_Type) could produce up to 3,600 pages per workday.*\n",
        "\n",
        "**Inference Costs:** The notebook also illustrates how to estimate OpenAI API costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97ljBFVtXkq"
      },
      "source": [
        "### 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SryUMoPdtXkq"
      },
      "source": [
        "#### 1.1 Install/Upgrade Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DTqUbA5mtXkr"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade openai --quiet\n",
        "%pip install --upgrade nlpia2-wikipedia --quiet\n",
        "%pip install --upgrade tenacity --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai  # for calling the OpenAI API\n",
        "import pandas as pd  # for storing text and embeddings data\n",
        "#import tiktoken  # for counting tokens"
      ],
      "metadata": {
        "id": "n8VxKOfZtwXu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=openai.api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "rPH8Du37t0ZT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5rOVQoctXks"
      },
      "source": [
        "#### 1.2 Load packages and OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uImgFA6tXkt"
      },
      "source": [
        "You can generate an API key in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zc5jdqxtXkt"
      },
      "source": [
        "This notebook works with the latest OpeanAI models `gpt-3.5-turbo-0613` and `gpt-4-0613`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cePG0C_QtXkt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import openai\n",
        "import wikipedia\n",
        "\n",
        "from typing import Optional\n",
        "from IPython.display import display, Markdown\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=' %(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "OPENAI_MODEL = 'gpt-3.5-turbo-0613'\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMbt-dD_tXku"
      },
      "source": [
        "### 2. Define the NER labels to be Identified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1FF7d__tXku"
      },
      "source": [
        "We define a standard set of NER labels to showcase a wide range of use cases. However, for our specific task of enriching text with knowledge base links, only a subset is practically required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8Ymu8FWrtXku"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"person\",      # people, including fictional characters\n",
        "    \"fac\",         # buildings, airports, highways, bridges\n",
        "    \"org\",         # organizations, companies, agencies, institutions\n",
        "    \"gpe\",         # geopolitical entities like countries, cities, states\n",
        "    \"loc\",         # non-gpe locations\n",
        "    \"product\",     # vehicles, foods, appareal, appliances, software, toys\n",
        "    \"event\",       # named sports, scientific milestones, historical events\n",
        "    \"work_of_art\", # titles of books, songs, movies\n",
        "    \"law\",         # named laws, acts, or legislations\n",
        "    \"language\",    # any named language\n",
        "    \"date\",        # absolute or relative dates or periods\n",
        "    \"time\",        # time units smaller than a day\n",
        "    \"percent\",     # percentage (e.g., \"twenty percent\", \"18%\")\n",
        "    \"money\",       # monetary values, including unit\n",
        "    \"quantity\",    # measurements, e.g., weight or distance\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjJW_pMCtXkv"
      },
      "source": [
        "### 3. Prepare messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZy9IRbtXkv"
      },
      "source": [
        "The [chat completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api) takes a list of messages as input and delivers a model-generated message as an output. While the chat format is primarily designed for facilitating multi-turn conversations, it is equally efficient for single-turn tasks without any preceding conversation. For our purposes, we will specify a message for the system, assistant, and user roles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-dP1Z-ZtXkv"
      },
      "source": [
        "#### 3.1 System Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hvSImmotXkv"
      },
      "source": [
        "The `system message` (prompt) sets the assistant's behavior by defining its desired persona and task. We also delineate the specific set of entity labels we aim to identify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o6V1R0ItXkv"
      },
      "source": [
        "Although one can instruct the model to format its response, it has to be noted that both `gpt-3.5-turbo-0613` and `gpt-4-0613` have been fine-tuned to discern when a function should be invoked, and to reply with `JSON` formatted according to the function's signature. This capability streamlines our prompt and enables us to receive structured data directly from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "aavpd7sAtXkv"
      },
      "outputs": [],
      "source": [
        "def system_message(labels):\n",
        "    return f\"\"\"\n",
        "You are an expert in Natural Language Processing. Your task is to identify common Named Entities (NER) in a given text.\n",
        "The possible common Named Entities (NER) types are exclusively: ({\", \".join(labels)}).\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoXq5o0StXkv"
      },
      "source": [
        "#### 3.2 Assistant Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll-RTAowtXkw"
      },
      "source": [
        "`Assistant messages` usually store previous assistant responses. However, as in our scenario, they can also be crafted to provide examples of the desired behavior. While OpenAI is able to execute `zero-shot` Named Entity Recognition, we have found that a `one-shot` approach produces more precise results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T_tdQbcstXkw"
      },
      "outputs": [],
      "source": [
        "def assisstant_message():\n",
        "    return f\"\"\"\n",
        "EXAMPLE:\n",
        "    Text: 'In Germany, in 1440, goldsmith Johannes Gutenberg invented the movable-type printing press. His work led to an information revolution and the unprecedented mass-spread /\n",
        "    of literature throughout Europe. Modelled on the design of the existing screw presses, a single Renaissance movable-type printing press could produce up to 3,600 pages per workday.'\n",
        "    {{\n",
        "        \"gpe\": [\"Germany\", \"Europe\"],\n",
        "        \"date\": [\"1440\"],\n",
        "        \"person\": [\"Johannes Gutenberg\"],\n",
        "        \"product\": [\"movable-type printing press\"],\n",
        "        \"event\": [\"Renaissance\"],\n",
        "        \"quantity\": [\"3,600 pages\"],\n",
        "        \"time\": [\"workday\"]\n",
        "    }}\n",
        "--\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYuhKmLWtXkw"
      },
      "source": [
        "#### 3.3 User Message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoBH8DHitXkw"
      },
      "source": [
        "The `user message` provides the specific text for the assistant task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t3KDUv0PtXkw"
      },
      "outputs": [],
      "source": [
        "def user_message(text):\n",
        "    return f\"\"\"\n",
        "TASK:\n",
        "    Text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-wXYvhRtXkw"
      },
      "source": [
        "### 4. OpenAI Functions (and Utils)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxU_GkPCtXkw"
      },
      "source": [
        "In an OpenAI API call, we can describe `functions` to `gpt-3.5-turbo-0613` and `gpt-4-0613` and have the model intelligently choose to output a `JSON` object containing arguments to call those `functions`. It's important to note that the [chat completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api) doesn't actually execute the `function`. Instead, it provides the `JSON` output, which can then be used to call the `function` in our code. For more details, refer to the [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/gpt/function-calling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkYShUsotXkx"
      },
      "source": [
        "Our function, `enrich_entities(text, label_entities` gets a block of text and a dictionary containing identified labels and entities as parameters. It then associates the recognized entities with their corresponding links to the Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "m7Ol_nAHtXkx"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(5))\n",
        "def find_link(entity: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Finds a Wikipedia link for a given entity.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        titles = wikipedia.search(entity)\n",
        "        if titles:\n",
        "            # naively consider the first result as the best\n",
        "            page = wikipedia.page(titles[0])\n",
        "            return page.url\n",
        "    except (wikipedia.exceptions.WikipediaException) as ex:\n",
        "        logging.error(f'Error occurred while searching for Wikipedia link for entity {entity}: {str(ex)}')\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "blHMjWsItXkx"
      },
      "outputs": [],
      "source": [
        "def find_all_links(label_entities:dict) -> dict:\n",
        "    \"\"\"\n",
        "    Finds all Wikipedia links for the dictionary entities in the whitelist label list.\n",
        "    \"\"\"\n",
        "    whitelist = ['event', 'gpe', 'org', 'person', 'product', 'work_of_art']\n",
        "\n",
        "    return {e: find_link(e) for label, entities in label_entities.items()\n",
        "                            for e in entities\n",
        "                            if label in whitelist}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RVd9iiintXkx"
      },
      "outputs": [],
      "source": [
        "def enrich_entities(text: str, label_entities: dict) -> str:\n",
        "    \"\"\"\n",
        "    Enriches text with knowledge base links.\n",
        "    \"\"\"\n",
        "    entity_link_dict = find_all_links(label_entities)\n",
        "    logging.info(f\"entity_link_dict: {entity_link_dict}\")\n",
        "\n",
        "    for entity, link in entity_link_dict.items():\n",
        "        text = text.replace(entity, f\"[{entity}]({link})\")\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQi1S0PMtXky"
      },
      "source": [
        "### 4. ChatCompletion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4oYFg0tXky"
      },
      "source": [
        "As previously highlighted, `gpt-3.5-turbo-0613` and `gpt-4-0613` have been fine-tuned to detect when a `function` should to be called. Moreover, they can produce a `JSON` response that conforms to the `function` signature. Here's the sequence we follow:\n",
        "\n",
        "1. Define our `function` and its associated `JSON` Schema.\n",
        "2. Invoke the model using the `messages`, `functions` and `function_call` parameters.\n",
        "3. Convert the output into a `JSON` object, and then call the `function` with the `arguments` provided by the model.\n",
        "\n",
        "In practice, one might want to re-invoke the model again by appending the `function` response as a new message, and let the model summarize the results back to the user. Nevertheless, for our purposes, this step is not needed.\n",
        "\n",
        "*Note that in a real-case scenario it is strongly recommended to build in user confirmation flows before taking actions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmV21wdwtXky"
      },
      "source": [
        "#### 4.1 Define our Function and JSON schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w6teDw2tXky"
      },
      "source": [
        "Since we want the model to output a dictionary of labels and recognized entities:\n",
        "\n",
        "```python\n",
        "{   \n",
        "    \"gpe\": [\"Germany\", \"Europe\"],   \n",
        "    \"date\": [\"1440\"],   \n",
        "    \"person\": [\"Johannes Gutenberg\"],   \n",
        "    \"product\": [\"movable-type printing press\"],   \n",
        "    \"event\": [\"Renaissance\"],   \n",
        "    \"quantity\": [\"3,600 pages\"],   \n",
        "    \"time\": [\"workday\"]   \n",
        "}   \n",
        "```\n",
        "we need to define the corresponding `JSON` schema to be passed to the `functions` parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hozlrB7ztXky"
      },
      "outputs": [],
      "source": [
        "def generate_functions(labels: dict) -> list:\n",
        "    return [\n",
        "        {\n",
        "            \"name\": \"enrich_entities\",\n",
        "            \"description\": \"Enrich Text with Knowledge Base Links\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"r'^(?:' + '|'.join({labels}) + ')$'\":\n",
        "                        {\n",
        "                            \"type\": \"array\",\n",
        "                            \"items\": {\n",
        "                                \"type\": \"string\"\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    \"additionalProperties\": False\n",
        "            },\n",
        "        }\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "The members of the Council of Denmark seem to have developed from being councillors of the king to being representatives of the magnates\n",
        "and noblemen. From the 1320s it clearly appears as a force, and from the 1440s it was the permanent opponent of royal power, replacing the\n",
        "Danehof.\n",
        "\n",
        "The Council consisted of noblemen who were appointed either by the king or their peers on the council. Until the 1536 Reformation, bishops\n",
        "were automatically members. So were the supreme officials (today the \"cabinet ministers\") while lower ranking \"ministers\" did not have any\n",
        "formal right to membership. The \"backbenchers\" of the council took part in daily negotiations of problems and administration, voted, and took\n",
        "on diplomatic tasks. Most of them were squires who also had to look after their lands.\n",
        "\n",
        "As a whole, it was the role of the council to rule together with the king, to control him, and to manage the affairs of State well. The\n",
        "councillors were seen as a guarantee towards the nobility (and in theory also towards \"the people\") that everything was done right. The\n",
        "Council took over the rule in the space that appeared by a succession or at interregna. It led negotiations over the creation of a new\n",
        "haandfæstning, and in theory it also had to call for a rebellion against kings who did not keep their promises, a right that was used in 1523.\n",
        "However, in the 16th century, it was not quite unusual that the councillors to some degree identified with the State rejecting too extravagant\n",
        "demands from the Danish gentry. The background of this normally was that they themselves represented the Danish answer to the peerage.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "unIRCVDquK5-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_gpt_function = [\n",
        "        {\n",
        "            \"name\": \"find_ner\",\n",
        "            \"description\": \"Extracts named entities and their categories from the input text.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"entities\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"entity\":{\"type\": \"string\",\n",
        "                                          \"description\": \"A Named entity extracted from text.\"},\n",
        "                                \"catrgory\":{\"type\": \"string\",\n",
        "                                            \"description\": \"Category of the named entity.\"}\n",
        "                            }\n",
        "                          }\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"entities\"]\n",
        "            }\n",
        "        ]"
      ],
      "metadata": {
        "id": "8cGu7NAiuQAU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\"role\": \"user\", \"content\": input_text}],\n",
        "        functions=ner_gpt_function,\n",
        "        function_call={\"name\": \"find_ner\"},\n",
        ")"
      ],
      "metadata": {
        "id": "QrDwR4-JuaFw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(response['choices'][0]['message']['function_call']['arguments'])\n",
        "#print(response)\n",
        "print(response.choices[0].message.function_call.arguments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2An_vjfnunbv",
        "outputId": "aec07fa8-0df0-470e-951e-c025cf687085"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"entities\": [\n",
            "    {\n",
            "      \"entity\": \"Council of Denmark\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"Danehof\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"cabinet ministers\",\n",
            "      \"category\": \"JOB\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"ministers\",\n",
            "      \"category\": \"JOB\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"backbenchers\",\n",
            "      \"category\": \"JOB\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"State\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"nobility\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"people\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"haandfæstning\",\n",
            "      \"category\": \"LAW\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"Danish gentry\",\n",
            "      \"category\": \"ORG\"\n",
            "    },\n",
            "    {\n",
            "      \"entity\": \"peerage\",\n",
            "      \"category\": \"ORG\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6MWvSZmtXky"
      },
      "source": [
        "#### 4.2 Chat Completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoaYuUH_tXkz"
      },
      "source": [
        "Now, we invoke the model. It's important to note that we direct the API to use a specific function by setting the `function_call` parameter to `{\"name\": \"enrich_entities\"}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "6SMLJkXTtXkz"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(5))\n",
        "def run_openai_task(labels, text):\n",
        "    messages = [\n",
        "          {\"role\": \"system\", \"content\": system_message(labels=labels)},\n",
        "          {\"role\": \"assistant\", \"content\": assisstant_message()},\n",
        "          {\"role\": \"user\", \"content\": user_message(text=text)}\n",
        "      ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\", #\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "        functions=generate_functions(labels),\n",
        "        function_call={\"name\": \"enrich_entities\"},\n",
        "        temperature=0,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message #response[\"choices\"][0][\"message\"]\n",
        "    print(response_message)\n",
        "    available_functions = {\"enrich_entities\": enrich_entities}\n",
        "    function_name = response_message.function_call.name\n",
        "    print(function_name)\n",
        "\n",
        "    function_to_call = available_functions[function_name]\n",
        "    logging.info(f\"function_to_call: {function_to_call}\")\n",
        "    print(function_to_call)\n",
        "    function_args = json.loads(response_message.function_call.arguments)\n",
        "    logging.info(f\"function_args: {function_args}\")\n",
        "\n",
        "    function_response = function_to_call(text, function_args)\n",
        "\n",
        "    return {\"model_response\": response,\n",
        "            \"function_response\": function_response}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqFARjp-yqcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0S21TBQtXkz"
      },
      "source": [
        "### 5. Let's Enrich a Text with Wikipedia links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xegOinzTtXk4"
      },
      "source": [
        "#### 5.1 Run OpenAI Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFHrT6JztXk4",
        "outputId": "5aaf4b6a-f675-40d6-ffe2-d35ee202cdd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"English\", \"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None)\n",
            "enrich_entities\n",
            "<function enrich_entities at 0x7e89ea63dea0>\n",
            "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"English\", \"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None)\n",
            "enrich_entities\n",
            "<function enrich_entities at 0x7e89ea63dea0>\n",
            "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"English\", \"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None)\n",
            "enrich_entities\n",
            "<function enrich_entities at 0x7e89ea63dea0>\n",
            "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"English\", \"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None)\n",
            "enrich_entities\n",
            "<function enrich_entities at 0x7e89ea63dea0>\n",
            "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None)\n",
            "enrich_entities\n",
            "<function enrich_entities at 0x7e89ea63dea0>\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"The Beatles were an English rock band formed in Liverpool in 1960, comprising John Lennon, Paul McCartney, George Harrison, and Ringo Starr.\"\"\"\n",
        "result = run_openai_task(labels, text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n",
        "print(result[\"model_response\"].choices[0])"
      ],
      "metadata": {
        "id": "9iysUTOLz2cu",
        "outputId": "470d36fb-2507-4cba-cdbf-80918095ea7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_response': ChatCompletion(id='chatcmpl-8VYbMVml5HeFRf7mjeWuzqCkKT3qg', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None))], created=1702531868, model='gpt-4-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=48, prompt_tokens=331, total_tokens=379)), 'function_response': '[The Beatles](https://en.wikipedia.org/wiki/The_Beatles) were an English rock band formed in [Liverpool](https://en.wikipedia.org/wiki/Liverpool) in 1960, comprising [John Lennon](https://en.wikipedia.org/wiki/John_Lennon), [Paul McCartney](https://en.wikipedia.org/wiki/Paul_McCartney), [George Harrison](https://en.wikipedia.org/wiki/George_Harrison), and [Ringo Starr](https://en.wikipedia.org/wiki/Ringo_Starr).'}\n",
            "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='\\n{\\n    \"org\": [\"The Beatles\"],\\n    \"gpe\": [\"Liverpool\"],\\n    \"date\": [\"1960\"],\\n    \"person\": [\"John Lennon\", \"Paul McCartney\", \"George Harrison\", \"Ringo Starr\"]\\n}', name='enrich_entities'), tool_calls=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzG7Y60MtXk4"
      },
      "source": [
        "#### 5.2 Function Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "YPB4TLI9tXk4",
        "outputId": "95ebd1c5-fc72-4cd9-c196-77d3e0caacd3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Text:** The Beatles were an English rock band formed in Liverpool in 1960, comprising John Lennon, Paul McCartney, George Harrison, and Ringo Starr.   \n                     **Enriched_Text:** [The Beatles](https://en.wikipedia.org/wiki/The_Beatles) were an English rock band formed in [Liverpool](https://en.wikipedia.org/wiki/Liverpool) in 1960, comprising [John Lennon](https://en.wikipedia.org/wiki/John_Lennon), [Paul McCartney](https://en.wikipedia.org/wiki/Paul_McCartney), [George Harrison](https://en.wikipedia.org/wiki/George_Harrison), and [Ringo Starr](https://en.wikipedia.org/wiki/Ringo_Starr)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(f\"\"\"**Text:** {text}\n",
        "                     **Enriched_Text:** {result['function_response']}\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Uu0od-tXk4"
      },
      "source": [
        "#### 5.3 Token Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPlb0I5ztXk5"
      },
      "source": [
        "To estimate the inference costs, we can parse the response's \"usage\" field. Detailed token costs per model are available in the [OpenAI Pricing Guide](https://openai.com/pricing):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "8acMsTFAtXk5",
        "outputId": "665baa1c-7254-4faa-9a3e-88e2fd9b30d1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-947eabb87acf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# estimate inference cost assuming gpt-3.5-turbo (4K context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mi_tokens\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mo_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completion_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi_tokens\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.0015\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletion' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# estimate inference cost assuming gpt-3.5-turbo (4K context)\n",
        "i_tokens  = result[\"model_response\"][\"usage\"][\"prompt_tokens\"]\n",
        "o_tokens = result[\"model_response\"][\"usage\"][\"completion_tokens\"]\n",
        "\n",
        "i_cost = (i_tokens / 1000) * 0.0015\n",
        "o_cost = (o_tokens / 1000) * 0.002\n",
        "\n",
        "print(f\"\"\"Token Usage\n",
        "    Prompt: {i_tokens} tokens\n",
        "    Completion: {o_tokens} tokens\n",
        "    Cost estimation: ${round(i_cost + o_cost, 5)}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VK4GqySszv-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}